{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#Initial Imports\n",
    "import gzip#; print('gzip version: ', gzip.__version__)\n",
    "import os#; print('os version: ', os.__version__)\n",
    "import re#; print('re version: ', re.__version__)\n",
    "import shutil#; print('shutil version: ', shutil.__version__)\n",
    "import requests#; print('requests version: ', requests.__version__)\n",
    "import wget#; print('wget version: ', wget.__version__)\n",
    "import subprocess#; print('subprocess version: ', subprocess.__version__)\n",
    "import time#; print('time version: ', time.__version__)\n",
    "from datetime import datetime\n",
    "from subprocess import PIPE, Popen\n",
    "import os.path\n",
    "from os import path\n",
    "from Bio.ExPASy import Enzyme\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Unitprot.fasta for Use in Diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_to_fasta():\n",
    "    reference_library = 'uniprot.tsv' \n",
    "    #this creates a file named 'uniprot.tsv' on the working directory. Should show within the EcoDr/EcoDr folder. \n",
    "    ua = UserAgent()\n",
    "    header = {'User-Agent': str(ua.chrome)}\n",
    "    uniprot_url = 'https://rest.uniprot.org/uniprotkb/stream?fields=accession%2Cec%2Csequence&format=tsv&query=%28%28ec%3A*%29%29+AND+%28reviewed%3Atrue%29'\n",
    "    time.sleep(4)\n",
    "    uniprot = requests.get(uniprot_url, headers=header)\n",
    "    if uniprot.status_code == 200:\n",
    "        with open(reference_library, 'w+') as reference_library:\n",
    "            reference_library.write(uniprot.text)\n",
    "    print('Uniprot Reference File Has Been Created')\n",
    "####this step takes it the initial tsv and converts it to FASTA\n",
    "    input = os.path.abspath('uniprot.tsv')\n",
    "    output = 'uniprot.fasta'\n",
    "    with open(input, 'r') as input_file, open(output, 'w') as output_file:\n",
    "        header=next(input_file)\n",
    "        for line in input_file:\n",
    "            carrot = f'>{line}'\n",
    "            new_row = re.sub(r'(.*?\\t.*?)\\t', r'\\1\\n', carrot, 1)\n",
    "            new_row_with_tab_replaced_by_question_mark = new_row.replace(\"\\t\", \"?\")\n",
    "            # Be careful with the symbols used for replacement, as they have to align with the genomic summary string parsing\n",
    "            output_row_with_space_replaced_with_ampersand = new_row_with_tab_replaced_by_question_mark.replace(\"; \", \";_\")\n",
    "            #new_row2 = re.sub(r'(.*?\\t.*?)\\t', r'$', new_row, 0)\n",
    "            #this is regex, for the record. \n",
    "            output_file.write(output_row_with_space_replaced_with_ampersand)\n",
    "    print('FASTA has been created from TSV and is named', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniprot Reference File Has Been Created\n",
      "FASTA has been created from TSV and is named uniprot.fasta\n"
     ]
    }
   ],
   "source": [
    "tsv_to_fasta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EC List Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EC_extract():\n",
    "    ec_library = 'EC_library.csv' \n",
    "    ua = UserAgent()\n",
    "    header = {'User-Agent': str(ua.chrome)}\n",
    "    ec_url = 'https://ftp.expasy.org/databases/enzyme/enzyme.dat'\n",
    "    time.sleep(4)\n",
    "    ec = requests.get(ec_url, headers=header)\n",
    "    if ec.status_code == 200:\n",
    "        with open(ec_library, 'w+', newline='\\n') as ec_file:\n",
    "            ec_file.write(ec.text)\n",
    "###This step creates the list \n",
    "    handle = open(ec_library)\n",
    "    records = Enzyme.parse(handle)\n",
    "    ecnumbers = [record[\"ID\"] for record in records]\n",
    "    #print(type(ecnumbers)) #This is a list at this point in the code\n",
    "    path = os.path.abspath(ec_library)\n",
    "    with open(path, 'w+', newline='\\n') as csv_file:\n",
    "        #csv_file = csv.writer(csv_file)\n",
    "        for item in ecnumbers:\n",
    "            csv_file.write(item +'\\n')\n",
    "    print('EC list Has Been Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC list Has Been Created\n"
     ]
    }
   ],
   "source": [
    "EC_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diamond_impl(dest, name):\n",
    "    print(os.getcwd())\n",
    "    matches = ''\n",
    "    output_folder = dest \n",
    "    print(\"DIAMOND search library is: \", output_folder)\n",
    "    if os.path.isfile('reference.dmnd'):\n",
    "        print(\"Library Detected\")\n",
    "    # If not present, then creates a DIAMOND library by referencing the exact location where the Uniprot library is saved\n",
    "    # If there currently is no reference library (.dmnd), then command makedb creates a DIAMOND library\n",
    "    else:\n",
    "        print(\"Creation of DIAMOND-formatted library...\")\n",
    "        makedb = ['diamond', 'makedb', '--in', '/home/anna/Documents/EnCen/uniprot.fasta', '-d',\n",
    "                  'Uniprot_Reference_Library.dmnd']  # Reference library full pathway\n",
    "        #This is a list for the DIAMOND specific makedb function. \n",
    "        subprocess.run(makedb)\n",
    "        #This simply runs the function makedb\n",
    "        print(\"Library complete\")\n",
    "#^this chunk is good to go. Just makes the reference database from the uniprot fasta. \n",
    "##_______________________________________________________________# This portion does the matching. The above portion creates the reference library from the unitprot fasta\n",
    "    for item in os.listdir(dest):\n",
    "        # Checks for file extension\n",
    "        if item.endswith('.faa') and not os.path.isfile(\n",
    "                os.path.basename(os.path.abspath(item)).rsplit('.', 1)[0] + \"_matches.tsv\"):\n",
    "            # Finds path of file\n",
    "            file_path = os.path.abspath(item)\n",
    "            # Finds the GCF/ASM name of the file by looking at the first part of the name before the .faa notation\n",
    "            if name == \"\":\n",
    "                print(os.path.basename(file_path).rsplit('.',1))\n",
    "                file_name = (os.path.basename(file_path)).rsplit('.', 1)[0]\n",
    "            else:\n",
    "                file_name = name\n",
    "            # New filename that ends with matches\n",
    "            matches = file_name + \"_matches.tsv\"\n",
    "            print(matches)\n",
    "            # If genome has not already undergone DIAMOND search and is currently located in the correct folder, then\n",
    "            # the subprocess function will run the diamond search\n",
    "\n",
    "\n",
    "            \n",
    "            if not os.path.isfile(dest + \"/\" + matches) and os.path.abspath(matches) != output_folder:\n",
    "                print(\"Processing \", file_name)\n",
    "                # DIAMOND search using the full pathway of the protein files, max target sequence outputs only one best\n",
    "                # match with highest e-value which represent the chance of obtaining a better random match in the same database (Buchfink et al, 2021)\n",
    "                blastp = ['diamond', 'blastp', '-d', 'Uniprot_Reference_Library.dmnd', '-q', file_path, '-o', matches,\n",
    "                          '--max-target-seqs', '1', '--outfmt', '6']\n",
    "                time.sleep(4)\n",
    "                subprocess.run(blastp)\n",
    "        # (2) Creates a folder for DIAMOND outputs\n",
    "        #if not os.path.exists(output_folder):\n",
    "            #os.makedirs('DIAMOND_matches')\n",
    "\n",
    "    # Moves all DIAMOND search outputs into the folder\n",
    "        if item.endswith('_matches.tsv'):\n",
    "            if os.path.exists(os.path.join(output_folder, item)):\n",
    "                print(f\"Overwriting: {item}\")\n",
    "                os.remove(os.path.join(output_folder, item))\n",
    "            shutil.move(os.path.abspath(item), output_folder)\n",
    "    print(\"diamond_impl--success\")\n",
    "    # Returns the location of the DIAMOND matches folder\n",
    "    return output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genome_extractor(diamond_folder, name):\n",
    "    os.chdir(diamond_folder)\n",
    "    print(os.getcwd())\n",
    "    # Opens the list of of EC numbers\n",
    "    ec_open = np.loadtxt('/projects/jodo9280/EcoDr/EcoDr/EC_library.csv',\n",
    "                         dtype='str')\n",
    "    big_matrix = [\"Name_of_Genome\"]\n",
    "    # Asks user to input name for EC matrix\n",
    "    # input_name = input(\"Save EC binary summary matrix as (no spaces or capital letters): \")\n",
    "    # Specifies document to be a csv type\n",
    "    # file_name= input_name+\".csv\"\n",
    "    # file_name = \"synbio1_big_matrix.csv\"\n",
    "    if name == \"\":\n",
    "        file_name = os.path.abspath(diamond_folder).rsplit('/', 9)[4] + '_binary_matrix.txt'\n",
    "        print(os.path.abspath(diamond_folder).rsplit('/', 9))\n",
    "        print(file_name)\n",
    "    else:\n",
    "        file_name = name\n",
    "    new_dir = diamond_folder + '/' + file_name\n",
    "    # Checks to see if the document already exists using full pathway name\n",
    "    if os.path.exists(new_dir):\n",
    "        pass\n",
    "        #print(\"Summary Matrix exists\")\n",
    "        #return [new_dir, file_name]\n",
    "    else:\n",
    "        for ec_force in ec_open:\n",
    "            # Creates a horizontal header of all of the EC names\n",
    "            big_matrix.append(ec_force)\n",
    "        # Goes through all of the DIAMOND outputs in the folder\n",
    "        # Goes through all of the output files, each one is opened and read one line at a time. The lines are split to\n",
    "        # extract the EC numbers found in each line. If the EC number found in the DIAMOND output matches an\n",
    "        # EC entry in the list, the status is changed from a zero to a one. The binary status is catalogued horizontally\n",
    "        # for each genome, and following genomes are vertically stacked\n",
    "        for item in os.listdir(diamond_folder):\n",
    "            if item.endswith(\"_matches.tsv\"):\n",
    "                print(item)\n",
    "                # Finds the name of the DIAMOND output file\n",
    "                genome = [item] #Turns the GCF's into a list, where the GCF names in the matrix come from. \n",
    "                genome_runner_ec = [item] #Turns the GCF's into a list, where the EC is appended\n",
    "                # Iterates through all of the EC numbers (1:8197)\n",
    "                \n",
    "                GCF = open(item, 'r') # CBM Added\n",
    "                \n",
    "                for line in GCF: # CBM Added\n",
    "                    no_tab = line.split('\\t')\n",
    "                    first_ec = no_tab[1].split(\"?\")\n",
    "                    separate_ec = first_ec[1].split(\";_\")\n",
    "                    genome_runner_ec.append(separate_ec)\n",
    "                    print(\"Appending...\")\n",
    "\n",
    "                for ec in ec_open:\n",
    "                    # print(\"EC we actually are looking for \"+ ec)\n",
    "                    # Opens individual DIAMOND output files\n",
    "                    #CBM GCF = open(item, 'r')\n",
    "                    # Sets default for EC status is zero, meaning absent\n",
    "                    #CBM ec_now = 0\n",
    "                    # Takes the first line in the DIAMOND output file and splits it based on tab separation\n",
    "                    # Takes the second column of the split line, which has EC numbers separated by a ?, ;_\n",
    "                    # Strings splits have a new name assigned to them\n",
    "                    #CBM for line in GCF:\n",
    "                    #CBM    print(line)\n",
    "                    #CBM    no_tab = line.split('\\t')\n",
    "                    #CBM    first_ec = no_tab[1].split(\"?\")\n",
    "                    #CBM    separate_ec = first_ec[1].split(\";_\")\n",
    "                    #CBM    print(\"Seperate EC Likely Nightmare \"+ separate_ec[0])\n",
    "                        # Checks for a full match between the EC number listed in the DIAMOND output and the EC number\n",
    "                        # found in the separate document\n",
    "                    #CBM    if re.fullmatch(ec, first_ec[1]) is not None:  # looks for full match of first EC number\n",
    "                    #CBM        ec_now = 1\n",
    "                        # In the case that there are more than one EC separated by ;, the function iterates through the list\n",
    "                        # and sees if there is a full match between the listed EC and the list\n",
    "                    #CBM    for i in separate_ec:\n",
    "                    #CBM        if re.fullmatch(ec, i) is not None:  # looks for full match of any other ECs listed\n",
    "                    #CBM            ec_now = 1\n",
    "                    ec_now = 0\n",
    "                    if [ec] in genome_runner_ec:\n",
    "                        ec_now = 1\n",
    "\n",
    "                    # 1 or 0 will be appended to the summary matrix for each EC value in the list\n",
    "                    genome.append(ec_now)\n",
    "                    #print(genome)\n",
    "                # Vertical stacking occurs for each genome in the DIAMOND output folder\n",
    "                big_matrix = np.vstack([big_matrix, genome])\n",
    "        #print(big_matrix)\n",
    "        # Saves matrix as a text file for further analysis\n",
    "        np.savetxt(file_name, big_matrix, fmt='%s')\n",
    "        # Returns the location of the summary matrix and the name of the file\n",
    "        if not os.path.exists('/projects/jodo9280/EcoDr/EcoDr/EcoDr_binary_matrix.txt'):\n",
    "            shutil.move(os.path.abspath('EcoDr_binary_matrix.txt'),'/projects/jodo9280/EcoDr/EcoDr')\n",
    "        else:\n",
    "            print('File already Exists')\n",
    "        print(new_dir)\n",
    "        return [new_dir, file_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I know things beyond the Maginot line are harried. \n",
      " But I worry. I've asked you time and time again. \n",
      "  Abandon your cataloging. \n",
      " Come Back Inside, where my fleets can keep you safe\n",
      "Come Home\n"
     ]
    }
   ],
   "source": [
    "print('I know things beyond the Maginot line are harried. \\n But I worry. I\\'ve asked you time and time again. \\n  Abandon your cataloging. \\n Come Back Inside, where my fleets can keep you safe')\n",
    "print('Come Home')\n",
    "metagenome_name = 'metagenome_analysis_output' #-> folder\n",
    "desired_location = '/home/anna/Documents/JGI_soil_genomes' \n",
    "# Freshwater = nump/nump/nump/files\n",
    "soil = '/home/anna/Documents/JGI_soil_genomes'\n",
    "abspath = os.path.abspath(soil)\n",
    "\n",
    "\n",
    "\n",
    "#______________________________________________________________#\n",
    "os.chdir(desired_location) #-> we are in the folder we want\n",
    "if os.path.exists(metagenome_name):\n",
    "    shutil.rmtree(metagenome_name)\n",
    "    os.mkdir(metagenome_name)\n",
    "else:#makes a new directory called metagenome_name\n",
    "    os.mkdir(metagenome_name)\n",
    "desired_location = desired_location + \"/\" + metagenome_name #-> this will make a folder called 'metagenome_analysis_output' within the 'desired_location' \n",
    "\n",
    "# shutil.copy(abspath, desired_location) #moves  file to Test Cases folder\n",
    "#matches = metagenome + \"_matches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anna/Documents/JGI_soil_genomes\n",
      "DIAMOND search library is:  /home/anna/Documents/JGI_soil_genomes\n",
      "Creation of DIAMOND-formatted library...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "diamond v0.9.30.131 (C) Max Planck Society for the Advancement of Science\n",
      "Documentation, support and updates available at http://www.diamondsearch.org\n",
      "\n",
      "#CPU threads: 20\n",
      "Scoring parameters: (Matrix=BLOSUM62 Lambda=0.267 K=0.041 Penalties=11/1)\n",
      "Database file: /home/anna/Documents/EnCen/uniprot.fasta\n",
      "Opening the database file...  [0s]\n",
      "Loading sequences...  [0.549s]\n",
      "Masking sequences...  [0.993s]\n",
      "Writing sequences...  [0.149s]\n",
      "Hashing sequences...  [0.067s]\n",
      "Loading sequences...  [0s]\n",
      "Writing trailer...  [0.003s]\n",
      "Closing the input file...  [0s]\n",
      "Closing the database file...  [0s]\n",
      "Database hash = 9ae9565aeffc045297d8444896762120\n",
      "Processed 275960 sequences, 114276793 letters.\n",
      "Total time = 1.763s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library complete\n",
      "['2162886007_5', 'faa']\n",
      "2162886007_5_matches.tsv\n",
      "Processing  2162886007_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "diamond v0.9.30.131 (C) Max Planck Society for the Advancement of Science\n",
      "Documentation, support and updates available at http://www.diamondsearch.org\n",
      "\n",
      "#CPU threads: 20\n",
      "Scoring parameters: (Matrix=BLOSUM62 Lambda=0.267 K=0.041 Penalties=11/1)\n",
      "Temporary directory: \n",
      "Opening the database...  [0s]\n",
      "#Target sequences to report alignments for: 1\n",
      "Reference = Uniprot_Reference_Library.dmnd\n",
      "Sequences = 275960\n",
      "Letters = 114276793\n",
      "Block size = 2000000000\n",
      "Opening the input file...  [0s]\n",
      "Opening the output file...  [0s]\n",
      "Loading query sequences...  [0.005s]\n",
      "Masking queries...  [0.011s]\n",
      "Building query seed set...  [0.01s]\n",
      "Algorithm: Double-indexed\n",
      "Building query histograms...  [0.004s]\n",
      "Allocating buffers...  [0s]\n",
      "Loading reference sequences...  [0.148s]\n",
      "Masking reference...  [0.95s]\n",
      "Initializing temporary storage...  [0s]\n",
      "Building reference histograms...  [0.32s]\n",
      "Allocating buffers...  [0s]\n",
      "Processing query block 0, reference block 0, shape 0, index chunk 0.\n",
      "Building reference seed array...  [0.221s]\n",
      "Building query seed array...  [0.003s]\n",
      "Computing hash join...  [0.03s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.022s]\n",
      "Processing query block 0, reference block 0, shape 0, index chunk 1.\n",
      "Building reference seed array...  [0.259s]\n",
      "Building query seed array...  [0.003s]\n",
      "Computing hash join...  [0.029s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.019s]\n",
      "Processing query block 0, reference block 0, shape 0, index chunk 2.\n",
      "Building reference seed array...  [0.25s]\n",
      "Building query seed array...  [0.004s]\n",
      "Computing hash join...  [0.031s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.016s]\n",
      "Processing query block 0, reference block 0, shape 0, index chunk 3.\n",
      "Building reference seed array...  [0.199s]\n",
      "Building query seed array...  [0.002s]\n",
      "Computing hash join...  [0.029s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.021s]\n",
      "Processing query block 0, reference block 0, shape 1, index chunk 0.\n",
      "Building reference seed array...  [0.208s]\n",
      "Building query seed array...  [0.003s]\n",
      "Computing hash join...  [0.029s]\n",
      "Building seed filter...  [0s]\n",
      "Searching alignments...  [0.018s]\n",
      "Processing query block 0, reference block 0, shape 1, index chunk 1.\n",
      "Building reference seed array...  [0.248s]\n",
      "Building query seed array...  [0.004s]\n",
      "Computing hash join...  [0.028s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.017s]\n",
      "Processing query block 0, reference block 0, shape 1, index chunk 2.\n",
      "Building reference seed array...  [0.257s]\n",
      "Building query seed array...  [0.004s]\n",
      "Computing hash join...  [0.032s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.016s]\n",
      "Processing query block 0, reference block 0, shape 1, index chunk 3.\n",
      "Building reference seed array...  [0.196s]\n",
      "Building query seed array...  [0.003s]\n",
      "Computing hash join...  [0.03s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.016s]\n",
      "Deallocating buffers...  [0.02s]\n",
      "Computing alignments...  [0.528s]\n",
      "Deallocating reference...  [0.009s]\n",
      "Loading reference sequences...  [0s]\n",
      "Deallocating buffers...  [0s]\n",
      "Deallocating queries...  [0s]\n",
      "Loading query sequences...  [0s]\n",
      "Closing the input file...  [0s]\n",
      "Closing the output file...  [0s]\n",
      "Closing the database file...  [0s]\n",
      "Deallocating taxonomy...  [0s]\n",
      "Total time = 4.289s\n",
      "Reported 1823 pairwise alignments, 1826 HSPs.\n",
      "1823 queries aligned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3300000532_1', 'faa']\n",
      "3300000532_1_matches.tsv\n",
      "Processing  3300000532_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "diamond v0.9.30.131 (C) Max Planck Society for the Advancement of Science\n",
      "Documentation, support and updates available at http://www.diamondsearch.org\n",
      "\n",
      "#CPU threads: 20\n",
      "Scoring parameters: (Matrix=BLOSUM62 Lambda=0.267 K=0.041 Penalties=11/1)\n",
      "Temporary directory: \n",
      "Opening the database...  [0s]\n",
      "#Target sequences to report alignments for: 1\n",
      "Reference = Uniprot_Reference_Library.dmnd\n",
      "Sequences = 275960\n",
      "Letters = 114276793\n",
      "Block size = 2000000000\n",
      "Opening the input file...  [0s]\n",
      "Opening the output file...  [0s]\n",
      "Loading query sequences...  [0.004s]\n",
      "Masking queries...  [0.009s]\n",
      "Building query seed set...  [0.007s]\n",
      "Algorithm: Double-indexed\n",
      "Building query histograms...  [0.002s]\n",
      "Allocating buffers...  [0s]\n",
      "Loading reference sequences...  [0.186s]\n",
      "Masking reference...  [0.73s]\n",
      "Initializing temporary storage...  [0s]\n",
      "Building reference histograms...  [0.308s]\n",
      "Allocating buffers...  [0s]\n",
      "Processing query block 0, reference block 0, shape 0, index chunk 0.\n",
      "Building reference seed array...  [0.229s]\n",
      "Building query seed array...  [0.003s]\n",
      "Computing hash join...  [0.04s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.023s]\n",
      "Processing query block 0, reference block 0, shape 0, index chunk 1.\n",
      "Building reference seed array...  [0.255s]\n",
      "Building query seed array...  [0.003s]\n",
      "Computing hash join...  [0.04s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.02s]\n",
      "Processing query block 0, reference block 0, shape 0, index chunk 2.\n",
      "Building reference seed array...  [0.266s]\n",
      "Building query seed array...  [0.003s]\n",
      "Computing hash join...  [0.041s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.03s]\n",
      "Processing query block 0, reference block 0, shape 0, index chunk 3.\n",
      "Building reference seed array...  [0.208s]\n",
      "Building query seed array...  [0.003s]\n",
      "Computing hash join...  [0.041s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.022s]\n",
      "Processing query block 0, reference block 0, shape 1, index chunk 0.\n",
      "Building reference seed array...  [0.204s]\n",
      "Building query seed array...  [0.003s]\n",
      "Computing hash join...  [0.04s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.019s]\n",
      "Processing query block 0, reference block 0, shape 1, index chunk 1.\n",
      "Building reference seed array...  [0.254s]\n",
      "Building query seed array...  [0.004s]\n",
      "Computing hash join...  [0.038s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.017s]\n",
      "Processing query block 0, reference block 0, shape 1, index chunk 2.\n",
      "Building reference seed array...  [0.263s]\n",
      "Building query seed array...  [0.004s]\n",
      "Computing hash join...  [0.037s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.018s]\n",
      "Processing query block 0, reference block 0, shape 1, index chunk 3.\n",
      "Building reference seed array...  [0.22s]\n",
      "Building query seed array...  [0.002s]\n",
      "Computing hash join...  [0.039s]\n",
      "Building seed filter...  [0.001s]\n",
      "Searching alignments...  [0.017s]\n",
      "Deallocating buffers...  [0.022s]\n",
      "Computing alignments... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diamond_impl--success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [0.457s]\n",
      "Deallocating reference...  [0.012s]\n",
      "Loading reference sequences...  [0s]\n",
      "Deallocating buffers...  [0s]\n",
      "Deallocating queries...  [0s]\n",
      "Loading query sequences...  [0s]\n",
      "Closing the input file...  [0s]\n",
      "Closing the output file...  [0s]\n",
      "Closing the database file...  [0s]\n",
      "Deallocating taxonomy...  [0s]\n",
      "Total time = 4.176s\n",
      "Reported 1119 pairwise alignments, 1124 HSPs.\n",
      "1119 queries aligned.\n"
     ]
    }
   ],
   "source": [
    "diamond = diamond_impl(soil, '') #-> Takes in the path and directory\n",
    "# new_dir, saved_file_name = genome_extractor(desired_location, '') #-> At this point, we have the one hotted binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
